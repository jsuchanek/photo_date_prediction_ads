{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import maxvit_t, MaxVit_T_Weights\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 1. Settings\n",
        "device       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size   = 64\n",
        "num_epochs   = 7\n",
        "print_every  = 1   # print summary every N epochs\n",
        "best_acc     = 0.0\n",
        "\n",
        "# 2. Preprocessing: resize → center-crop → to-tensor → normalize (ImageNet stats)\n",
        "weights   = MaxVit_T_Weights.IMAGENET1K_V1\n",
        "preproc   = weights.transforms()\n",
        "\n",
        "# 3. Prepare CIFAR-10, but limit train → 5 000 images\n",
        "full_train_ds = datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=preproc\n",
        ")\n",
        "train_ds, _ = random_split(\n",
        "    full_train_ds,\n",
        "    [4000, len(full_train_ds) - 4000],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "train_ld = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "\n",
        "full_val_ds = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=preproc\n",
        ")\n",
        "val_ds, _ = random_split(\n",
        "    full_val_ds,\n",
        "    [800, len(full_val_ds) - 800],\n",
        "    generator=torch.Generator().manual_seed(42)  # for reproducibility\n",
        ")\n",
        "val_ld = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Training on classes:\", train_ds.dataset.classes)\n",
        "\n",
        "# 4. Model: load pretrained MaxViT-T, freeze everything, then append a new 1000→10 head\n",
        "model = maxvit_t(weights=weights).to(device)\n",
        "\n",
        "# 4a. Freeze all existing params\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 4b. Extract and rebuild classifier\n",
        "orig_classifier = model.classifier                  # Sequential([pool, flatten, Linear(512->1000)])\n",
        "layers = list(orig_classifier.children())\n",
        "old_linear = layers[-1]\n",
        "num_features = old_linear.out_features              # should be 1000\n",
        "\n",
        "# 4c. Append new head\n",
        "layers.append(nn.Linear(num_features, 10))\n",
        "model.classifier = nn.Sequential(*layers).to(device)\n",
        "\n",
        "# 4d. Unfreeze only the new head\n",
        "for param in model.classifier[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 5. Loss & optimizer (only new head’s params)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(\n",
        "    model.classifier[-1].parameters(),\n",
        "    lr=1e-2,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# 6. Training + validation loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # — Training —\n",
        "    model.train()\n",
        "    running_loss = correct = total = 0\n",
        "    for imgs, labels in train_ld:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct   += (preds == labels).sum().item()\n",
        "        total     += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc  = 100. * correct / total\n",
        "\n",
        "    # — Validation —\n",
        "    model.eval()\n",
        "    val_loss = val_correct = val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_ld:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            out = model(imgs)\n",
        "            val_loss    += criterion(out, labels).item() * imgs.size(0)\n",
        "            preds        = out.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total   += labels.size(0)\n",
        "\n",
        "    val_loss = val_loss / val_total\n",
        "    val_acc  = 100. * val_correct / val_total\n",
        "\n",
        "    # — Print stats —\n",
        "    if epoch % print_every == 0:\n",
        "        print(f\"Epoch {epoch}/{num_epochs} — \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f},   Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # — Save best model —\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_maxvit_cifar10.pth\")\n",
        "\n",
        "print(f\"\\nDone! Best validation accuracy: {best_acc:.2f}%\")\n",
        "print(\"Best model weights saved to best_maxvit_cifar10.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7lXaVYu2JOD",
        "outputId": "9f8c0f75-71e5-410a-b6f7-a9944c78849b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Epoch 1/7 — Train Loss: 0.7896, Train Acc: 75.03% | Val Loss: 0.3620,   Val Acc: 88.38%\n",
            "Epoch 2/7 — Train Loss: 0.4981, Train Acc: 83.75% | Val Loss: 0.3522,   Val Acc: 88.38%\n",
            "Epoch 3/7 — Train Loss: 0.4692, Train Acc: 84.20% | Val Loss: 0.4044,   Val Acc: 87.50%\n",
            "Epoch 4/7 — Train Loss: 0.4490, Train Acc: 85.45% | Val Loss: 0.3634,   Val Acc: 89.62%\n",
            "Epoch 5/7 — Train Loss: 0.3958, Train Acc: 86.80% | Val Loss: 0.4321,   Val Acc: 86.62%\n",
            "Epoch 6/7 — Train Loss: 0.3930, Train Acc: 86.80% | Val Loss: 0.4608,   Val Acc: 84.00%\n",
            "Epoch 7/7 — Train Loss: 0.3940, Train Acc: 86.35% | Val Loss: 0.4489,   Val Acc: 85.75%\n",
            "\n",
            "Done! Best validation accuracy: 89.62%\n",
            "Best model weights saved to best_maxvit_cifar10.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 1. Settings\n",
        "device       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size   = 64\n",
        "num_epochs   = 7\n",
        "print_every  = 1   # print summary every N epochs\n",
        "best_acc     = 0.0\n",
        "\n",
        "# 2. Preprocessing: resize → center-crop → to-tensor → normalize (ImageNet stats)\n",
        "weights   = ViT_B_16_Weights.IMAGENET1K_V1  # or ViT_B_16_Weights.DEFAULT, or \"DEFAULT\"\n",
        "preproc   = weights.transforms()\n",
        "\n",
        "# 3. Prepare CIFAR-10, but limit train → 4 000 images\n",
        "full_train_ds = datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=preproc\n",
        ")\n",
        "train_ds, _ = random_split(\n",
        "    full_train_ds,\n",
        "    [4000, len(full_train_ds) - 4000],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "train_ld = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "#    Limit validation → 800 images\n",
        "full_val_ds = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, download=True, transform=preproc\n",
        ")\n",
        "val_ds, _ = random_split(\n",
        "    full_val_ds,\n",
        "    [800, len(full_val_ds) - 800],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "val_ld = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Training on classes:\", train_ds.dataset.classes)\n",
        "\n",
        "# 4. Model: load pretrained ViT-B_16, freeze everything, then append a new 1000→10 head\n",
        "model = vit_b_16(weights=weights).to(device)\n",
        "\n",
        "# 4a. Freeze all existing params\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 4b. Extract and rebuild the classification head\n",
        "#     VisionTransformer stores its head in `model.heads`, a nn.Sequential\n",
        "orig_heads = model.heads                    # e.g. Sequential([LayerNorm, Linear(768→1000)])\n",
        "layers = list(orig_heads.children())\n",
        "old_linear = layers[-1]\n",
        "num_features = old_linear.out_features      # should be 1000\n",
        "\n",
        "# 4c. Append new 1000→10 Linear layer\n",
        "layers.append(nn.Linear(num_features, 10))\n",
        "model.heads = nn.Sequential(*layers).to(device)\n",
        "\n",
        "# 4d. Un-freeze only the new head\n",
        "for param in model.heads[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 5. Loss & optimizer (only new head’s parameters)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(\n",
        "    model.heads[-1].parameters(),\n",
        "    lr=1e-2,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# 6. Training + validation loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # — Training —\n",
        "    model.train()\n",
        "    running_loss = correct = total = 0\n",
        "    for imgs, labels in train_ld:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct   += (preds == labels).sum().item()\n",
        "        total     += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc  = 100. * correct / total\n",
        "\n",
        "    # — Validation —\n",
        "    model.eval()\n",
        "    val_loss = val_correct = val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_ld:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            out = model(imgs)\n",
        "            val_loss    += criterion(out, labels).item() * imgs.size(0)\n",
        "            preds        = out.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total   += labels.size(0)\n",
        "\n",
        "    val_loss = val_loss / val_total\n",
        "    val_acc  = 100. * val_correct / val_total\n",
        "\n",
        "    # — Print stats —\n",
        "    if epoch % print_every == 0:\n",
        "        print(f\"Epoch {epoch}/{num_epochs} — \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f},   Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # — Save best model —\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_vit_cifar10.pth\")\n",
        "\n",
        "print(f\"\\nDone! Best validation accuracy: {best_acc:.2f}%\")\n",
        "print(\"Best model weights saved to best_vit_cifar10.pth\")\n"
      ],
      "metadata": {
        "id": "IgyGIm975UBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "8163b6c6-6084-48a4-bded-1fb0aa63a240"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 13.0MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:01<00:00, 193MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 — Train Loss: 0.4493, Train Acc: 86.17% | Val Loss: 0.2667,   Val Acc: 93.00%\n",
            "Epoch 2/7 — Train Loss: 0.1839, Train Acc: 94.03% | Val Loss: 0.2407,   Val Acc: 92.62%\n",
            "Epoch 3/7 — Train Loss: 0.1455, Train Acc: 95.08% | Val Loss: 0.2353,   Val Acc: 92.25%\n",
            "Epoch 4/7 — Train Loss: 0.1184, Train Acc: 96.20% | Val Loss: 0.2316,   Val Acc: 92.50%\n",
            "Epoch 5/7 — Train Loss: 0.0991, Train Acc: 97.00% | Val Loss: 0.2290,   Val Acc: 93.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0c847f7100>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1582, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
            "    ready = selector.select(timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-900a007dc9f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mcorrect\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEe5r0qJ5Ir5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}